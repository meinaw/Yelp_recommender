{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data Challenge - NLP\n",
    "\n",
    "Meina Wang\n",
    "\n",
    "Mar 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/last_1_years_restaurant_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>categories</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Cajun/Creole, Steakhouses, Restaurants]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>0</td>\n",
       "      <td>Xp3ppynEvVu1KxDHQ3ae8w</td>\n",
       "      <td>5</td>\n",
       "      <td>Delmonico Steakhouse is a steakhouse owned by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>KC8H7qTZVPIEnanw9fG43g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Cajun/Creole, Steakhouses, Restaurants]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>LEzphAnz0vKE32PUCbjLgQ</td>\n",
       "      <td>4</td>\n",
       "      <td>One of the top steak places I've had in Vegas ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3RTesI_MAwct13LWm4rhLw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Cajun/Creole, Steakhouses, Restaurants]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>0</td>\n",
       "      <td>4e-cxYVdlIu2ZDxVJqUfOQ</td>\n",
       "      <td>5</td>\n",
       "      <td>This place is superb from the customer service...</td>\n",
       "      <td>0</td>\n",
       "      <td>EAOt1UQhJD0GG3l_jv7rWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Cajun/Creole, Steakhouses, Restaurants]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-12</td>\n",
       "      <td>1</td>\n",
       "      <td>heZd0W3HuPJxZBrCYD3wDw</td>\n",
       "      <td>2</td>\n",
       "      <td>Lousy steak. \\n\\nThe service was great - Todd,...</td>\n",
       "      <td>3</td>\n",
       "      <td>OtKA03ALQQ1CBhtaJod_Jw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--9e1ONYQuAa-CB_Rrw7Tw</td>\n",
       "      <td>Delmonico Steakhouse</td>\n",
       "      <td>[Cajun/Creole, Steakhouses, Restaurants]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-10</td>\n",
       "      <td>0</td>\n",
       "      <td>exzXjy7Y2ICX_BEVTDWpJA</td>\n",
       "      <td>5</td>\n",
       "      <td>I got the filet mignon with seared foigras and...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ymtd4cQypep_QZJ-qJsHuA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                  name  \\\n",
       "0  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "1  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "2  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "3  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "4  --9e1ONYQuAa-CB_Rrw7Tw  Delmonico Steakhouse   \n",
       "\n",
       "                                 categories  avg_stars  cool        date  \\\n",
       "0  [Cajun/Creole, Steakhouses, Restaurants]        4.0     0  2017-02-14   \n",
       "1  [Cajun/Creole, Steakhouses, Restaurants]        4.0     1  2017-05-28   \n",
       "2  [Cajun/Creole, Steakhouses, Restaurants]        4.0     0  2017-08-25   \n",
       "3  [Cajun/Creole, Steakhouses, Restaurants]        4.0     1  2017-02-12   \n",
       "4  [Cajun/Creole, Steakhouses, Restaurants]        4.0     0  2017-12-10   \n",
       "\n",
       "   funny               review_id  stars  \\\n",
       "0      0  Xp3ppynEvVu1KxDHQ3ae8w      5   \n",
       "1      0  LEzphAnz0vKE32PUCbjLgQ      4   \n",
       "2      0  4e-cxYVdlIu2ZDxVJqUfOQ      5   \n",
       "3      1  heZd0W3HuPJxZBrCYD3wDw      2   \n",
       "4      0  exzXjy7Y2ICX_BEVTDWpJA      5   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  Delmonico Steakhouse is a steakhouse owned by ...       0   \n",
       "1  One of the top steak places I've had in Vegas ...       2   \n",
       "2  This place is superb from the customer service...       0   \n",
       "3  Lousy steak. \\n\\nThe service was great - Todd,...       3   \n",
       "4  I got the filet mignon with seared foigras and...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  KC8H7qTZVPIEnanw9fG43g  \n",
       "1  3RTesI_MAwct13LWm4rhLw  \n",
       "2  EAOt1UQhJD0GG3l_jv7rWA  \n",
       "3  OtKA03ALQQ1CBhtaJod_Jw  \n",
       "4  Ymtd4cQypep_QZJ-qJsHuA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define feature variables, here is the text of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the values of the column that contains review text data, save to a variable named \"documents\"\n",
    "documents = df['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This place had the best appetizer (fried oysters and bone marrow spread) and one of the most perfectly cooked steaks I've had. Went here for New Year's with my family and we definitely enjoyed ourselves. It was a bit dark and formal for my liking but overall was a great culinary experience.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect your documents, e.g. check the size, take a peek at elements of the numpy array\n",
    "documents.dtype, documents.shape\n",
    "documents[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define target variable, here is the rating of the review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For example, I am interested in > 4 stars rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False,  True,  True,  True, False,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a column and take the values, save to a variable named \"target\"\n",
    "df['favorable'] = df['stars'] > 4\n",
    "target = df['favorable'].values\n",
    "target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((169917,), (169917,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training dataset and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meinawang/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to documents_train, documents_test, target_train, target_test\n",
    "documents_train, documents_test, target_train, target_test = train_test_split(\n",
    "    documents,\n",
    "    target,\n",
    "    test_size = 0.3,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get NLP representation of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TfidfVectorizer, and name it vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with your training data\n",
    "vectors_train = vectorizer.fit_transform(documents_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the vocab of your tfidf\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to transform your test data\n",
    "vectors_test = vectorizer.transform(documents_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar review search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_top_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the highest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"cat\", \"pig\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[::-1][:n]]  # np.argsort by default sorts values in ascending order\n",
    "\n",
    "def get_bottom_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the lowest n values.\n",
    "    Return the labels for each of these indices.\n",
    "\n",
    "    e.g.\n",
    "    lst = [7, 3, 2, 4, 1]\n",
    "    n = 2\n",
    "    labels = [\"cat\", \"dog\", \"mouse\", \"pig\", \"rabbit\"]\n",
    "    output: [\"mouse\", \"rabbit\"]\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[:n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw an arbitrary review from test (unseen in training) documents\n",
    "some_random_number = 42\n",
    "search_query = documents_test[some_random_number]\n",
    "search_queries = [search_query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the drawn review(s) to vector(s)\n",
    "vector_search_queries = vectorizer.transform(search_queries).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity score(s) between vector(s) and training vectors\n",
    "similarity_scores = cosine_similarity(vector_search_queries, vectors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find top 5 similar reviews\n",
    "n = 5\n",
    "returned_reviews = get_top_values(similarity_scores[0], n, documents_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our search query:\n",
      "Wow!! The Drag Queen Brunch was the highlight of my Vegas trip!\n",
      "\n",
      "My daughter is a HUGE fan Rupaul's Drag Race & some of the cast perform at this show. So she chose this as one of the activities to celebrate her 21st birthday in Las Vegas. \n",
      "\n",
      "A group of us gals bought tickets via groupon. You need to redeem both the ticket & groupon voucher there at the venue so make sure you have it (or on your phone). VIP's do not need to wait in the very long line.  So I highly recommend the VIP tix --- no waiting in line, you receive priority seating, unlimited alcohol at the bar in addition to unlimited mimosas, and their buffet. The buffet had many choices, such as waffles, eggs, bacon, cheese omelets, yogurt, tamales, taquitos, juices, coffee, etc. \n",
      "\n",
      "All of the performances were amazing & the show had great energy.  The host (dressed in red here in this pic) was my FAVE--very funny & so entertaining!!! \n",
      "\n",
      "The only thing we missed out on was the photo op that was included in our package. \n",
      "\n",
      "I would definitely go back to see this show again, you will LOVE IT!!! Thanks again!\n"
     ]
    }
   ],
   "source": [
    "print('Our search query:')\n",
    "print(search_queries[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most 5 similar reviews:\n",
      "This review is for the Drag Show Brunch at Se√±or Frogs only.\n",
      "\n",
      "This show was amazing!!!\n",
      "\n",
      "We arrived at 11:00 am for the 11:30 showing.  We started being checked in immediately, and were are able to get our food before the show.  While the Brunch Buffet was okay, the Drinks and entertainment far beyond make up for it.\n",
      "\n",
      "The Brunch Buffett has a wide variety of breakfast.....cereal, waffles, egg omelets, bacon, sausage, pancakes and also a Mexican lunch option which I wasn't very impressed with.  The lunch option was taquitos, tamales, rice, chimichangas.  They also had additional coffee and grapefruit juice plus fruit and yogurt.  So there is a wide range of food to choose from.  For me though I thought the breakfast was better than the Mexican lunch.\n",
      "\n",
      "The Drinks......So we bought our tickets and Groupon which you have to redeem both the Groupon and show tickets at the same time.  Also make sure you book the show tickets separately in advance.  Our Groupon was for $57 and the drinks alone were well worth it if you know how expensive a Vegas cocktail is.   If you get the VIP package which we did, we had the entire show of premium open bar plus unlimited mimosas available on the table.  Let me tell you the wait staff was amazing, our bottles on the table were never empty the second a bottle finished they were putting in a new one on ice.  The bartender was awesome, he was quick and those drinks were strong.  You can get seriously wasted during this 2 hour show and they strongly encourage it!!  Between my friends and I, we had 6-8 drinks from the bar each on top of what was on the table.  To top it off when the show is over they tell you to take the bottles on the table with you so many people walked out with full bottles of champagne.\n",
      "\n",
      "The actual show is AMAZING!!!!  These ladies were fabulous and didn't disappoint.  Chanelle the host will have you laughing from the get go.  The costumes and makeup are incredible.  They work the entire crowd so it didn't matter where you sat.  most performances start on stage and move into the crowd.  And yes they get tips,  but don't worry if you don't have smaller bills, before the show one of the hostesses will exchange you big bills for smaller ones.  And trust me once you see their talents you will be holding up dollar bills for your favorite performers.\n",
      "\n",
      "Also don't forget to tip your bartenders and wait staff.  They were all great kept our tables clear and our drinks full.  This was well worth it and we had a great time.  I would definitely recommend this show.\n"
     ]
    }
   ],
   "source": [
    "print('Most %s similar reviews:' % n)\n",
    "print(returned_reviews[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense for the above reviews to be similar, since they both mentioned the show is amazing, and the reviews are positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying positive/negative review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.817186672383787"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_nb.score(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8085765850596359"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model_nb.score(vectors_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lrc = LogisticRegression(random_state=42)\n",
    "model_lrc.fit(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8500012611294675"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for training set\n",
    "model_lrc.score(vectors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.832274011299435"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get score for test set\n",
    "model_lrc.score(vectors_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key features(words) that make the positive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'amazing',\n",
       " u'best',\n",
       " u'fantastic',\n",
       " u'awesome',\n",
       " u'delicious',\n",
       " u'thank',\n",
       " u'highly',\n",
       " u'perfect',\n",
       " u'incredible',\n",
       " u'perfection',\n",
       " u'excellent',\n",
       " u'phenomenal',\n",
       " u'love',\n",
       " u'great',\n",
       " u'outstanding',\n",
       " u'favorite',\n",
       " u'heaven',\n",
       " u'bomb',\n",
       " u'regret',\n",
       " u'wonderful']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find it out by ranking\n",
    "n = 20\n",
    "get_top_values(model_lrc.coef_[0], n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postive words make the positive prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key features(words) that make the negative prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'worst',\n",
       " u'ok',\n",
       " u'horrible',\n",
       " u'mediocre',\n",
       " u'rude',\n",
       " u'okay',\n",
       " u'disappointing',\n",
       " u'terrible',\n",
       " u'slow',\n",
       " u'bland',\n",
       " u'average',\n",
       " u'awful',\n",
       " u'dry',\n",
       " u'overpriced',\n",
       " u'poor',\n",
       " u'reason',\n",
       " u'lacking',\n",
       " u'meh',\n",
       " u'lacked',\n",
       " u'disgusting']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 20\n",
    "get_bottom_values(model_lrc.coef_[0], n, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative or not postive words make the negative prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cross validation to evaluate the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83446131, 0.83349447, 0.8363109 , 0.83747425, 0.83339639])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(model_lrc,\n",
    "                           vectors_train,\n",
    "                           target_train,\n",
    "                           cv = 5,\n",
    "                           scoring = 'accuracy')\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use grid search to find best predictable classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best parameters are: ', {'penalty': 'l2', 'C': 1})\n",
      "(0.506, 0.0040009999750162395, {'penalty': 'l1', 'C': 0.01})\n",
      "(0.506, 0.0040009999750162395, {'penalty': 'l1', 'C': 0.1})\n",
      "(0.676, 0.07936762767043122, {'penalty': 'l1', 'C': 1})\n",
      "(0.726, 0.058965838389780374, {'penalty': 'l1', 'C': 5})\n",
      "(0.724, 0.036226090500677814, {'penalty': 'l1', 'C': 10})\n",
      "(0.736, 0.038933250311244026, {'penalty': 'l1', 'C': 100})\n",
      "(0.548, 0.0247688302003738, {'penalty': 'l2', 'C': 0.01})\n",
      "(0.756, 0.08472858014406548, {'penalty': 'l2', 'C': 0.1})\n",
      "(0.78, 0.09214120142531253, {'penalty': 'l2', 'C': 1})\n",
      "(0.778, 0.10446326080151688, {'penalty': 'l2', 'C': 5})\n",
      "(0.778, 0.11194058544364931, {'penalty': 'l2', 'C': 10})\n",
      "(0.762, 0.11083482320915015, {'penalty': 'l2', 'C': 100})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "param_grid = [{'penalty':['l1'], 'C':[0.01, 0.1, 1, 5, 10, 100]},\n",
    "             {'penalty':['l2'], 'C':[0.01, 0.1, 1, 5, 10, 100]}]\n",
    "scores = ['accuracy']\n",
    "\n",
    "for score in scores:\n",
    "    clf = GridSearchCV(LogisticRegression(),\n",
    "                      param_grid,\n",
    "                      cv=5,\n",
    "                      scoring=score)\n",
    "    clf.fit(vectors_train[:500,:], target_train[:500])\n",
    "    print(\"Best parameters are: \", clf.best_params_)\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(mean, std * 2, params)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.78      0.76      0.77     25810\n",
      "       True       0.76      0.79      0.77     25166\n",
      "\n",
      "avg / total       0.77      0.77      0.77     50976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = target_test, clf.predict(vectors_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
